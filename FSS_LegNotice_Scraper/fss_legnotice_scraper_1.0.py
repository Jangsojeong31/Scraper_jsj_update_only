import os
import sys
import json
import time

# ==================================================
# üîë ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Îì±Î°ù
# ==================================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, ".."))

if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from common.common_logger import get_logger

# ==================================================
# Î°úÍ±∞
# ==================================================
logger = get_logger("fss_legnotice_selenium")

# ==================================================
# Selenium
# ==================================================
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager

from common.constants import URLStatus, LegalDocProvided
ORG_NAME = LegalDocProvided.FSS

# ==================================================
# URL / ÏÑ§Ï†ï
# ==================================================
LIST_URL = "https://www.fss.or.kr/fss/job/lrgRegItnPrvntc/list.do?menuNo=200489"

WAIT_TIMEOUT = 12
HEADLESS = True

OUTPUT_BASE_DIR = os.path.join(CURRENT_DIR, "output")
OUTPUT_JSON_DIR = os.path.join(OUTPUT_BASE_DIR, "json")
os.makedirs(OUTPUT_JSON_DIR, exist_ok=True)

JSON_OUTPUT = os.path.join(OUTPUT_JSON_DIR, "fss_legnotice_results.json")

# ==================================================
# Chrome Driver
# ==================================================
def create_driver():
    options = Options()

    if HEADLESS:
        options.add_argument("--headless=new")
        options.add_argument("--disable-gpu")

    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-extensions")
    options.add_argument("--log-level=3")

    return webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options
    )

# ==================================================
# ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄ Î≥∏Î¨∏ Ï∂îÏ∂ú (FULL TEXT ONLY)
# ==================================================
def parse_detail_full(driver):
    wait = WebDriverWait(driver, WAIT_TIMEOUT)

    try:
        box = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.box"))
        )
        return box.text.strip()

    except TimeoutException:
        logger.warning("ÏÉÅÏÑ∏ Î≥∏Î¨∏ Î°úÎî© Ïã§Ìå®")
        return ""

# ==================================================
# Ï†ÑÏ≤¥ Ïã§Ìñâ
# ==================================================
def scrape_all():
    logger.info("FSS Í∑úÏ†ï Í∞úÏ†ïÏòàÍ≥† (Selenium) Ïä§ÌÅ¨ÎûòÌïë ÏãúÏûë")

    driver = create_driver()
    wait = WebDriverWait(driver, WAIT_TIMEOUT)

    driver.get(LIST_URL)

    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr")))
    except TimeoutException:
        logger.error("Î™©Î°ù Î°úÎî© Ïã§Ìå®")
        driver.quit()
        return

    results = []

    rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
    total = len(rows)
    logger.info(f"Ï¥ù {total}Í±¥ Î∞úÍ≤¨")

    for idx in range(total):
        rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
        row = rows[idx]

        cols = row.find_elements(By.TAG_NAME, "td")
        if len(cols) < 3:
            continue

        title = cols[1].text.strip()
        date = cols[2].text.strip()

        link_el = cols[1].find_element(By.TAG_NAME, "a")

        logger.info(f"[{idx+1}/{total}] {title}")

        driver.execute_script("arguments[0].click();", link_el)
        time.sleep(1)

        detail_url = driver.current_url
        detail_full = parse_detail_full(driver)

        results.append({
            "org_name": ORG_NAME,
            "title": title,
            "date": date,
            "content": detail_full,
            "detail_url": detail_url
        })

        # Î™©Î°ù Î≥µÍ∑Ä (URL Ïû¨Ï†ëÍ∑º)
        driver.get(LIST_URL)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr")))

    with open(JSON_OUTPUT, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    logger.info(f"JSON Ï†ÄÏû• ÏôÑÎ£å: {JSON_OUTPUT}")
    driver.quit()

# ==================================================
# main
# ==================================================
if __name__ == "__main__":
    scrape_all()
