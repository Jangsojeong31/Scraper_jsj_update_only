# 금융감독원 제재조치 스크래핑 가이드

## 개요
금융감독원 제재조치 공개 정보를 자동으로 스크래핑하여 JSON 및 CSV 파일로 저장하는 프로젝트입니다.

## 현재 상태
- **전체 항목**: 260개
- **성공률**: 100% (일반 제재/재심/제재대상 없음 전체 성공)
- **문서유형 구분**: PDF-텍스트 / PDF-OCR / 기타 / 첨부없음 / URL없음 / 오류

## 주요 파일

### 1. `fss_sanctions_scraper.py`
- 메인 스크래핑 스크립트
- 모든 페이지를 순회하며 데이터 수집
- PDF 다운로드 및 텍스트 추출 (V3 하이브리드 OCR 포함)
- 메타데이터 추출 (금융회사명, 제재조치일, 제재내용, 사건목록)
- 결과를 `output/fss_sanc_result.json` 및 `output/fss_sanc_result.csv`로 저장

### 2. `ocr_extractor.py`
- V3 하이브리드 OCR 추출 모듈
- 표 형식: v2 방식 (500 DPI, 강한 전처리)
- 문단 형식: v1 방식 (300 DPI, 최소 전처리)
- 자동 감지로 최적 방식 선택

### 3. `post_process_ocr.py`
- OCR 후처리 및 품질 검증 스크립트
- OCR 인공물 제거, 알려진 문제 자동 수정
- 누락필드 계산 및 품질 검증 리포트 출력

### 4. `extract_metadata.py`
- PDF 텍스트에서 메타데이터 추출
- 금융회사명, 제재조치일, 제재내용(표 데이터), 사건목록 추출
- OCR/일반 텍스트 모두 동일한 함수 사용

### 5. `run_pipeline.py`
- 전체 파이프라인 자동 실행 스크립트
- 실행 순서:
  1. `fss_sanctions_scraper.py`: 스크래핑 및 메타데이터 추출
  2. `post_process_ocr.py`: OCR 후처리 (새로 크롤링한 데이터)
  3. archive 병합: OCR 후처리된 데이터를 `archive/fss_sanc_result.json`과 병합
  4. 통계 출력: 제재내용 추출 성공률 출력
- 주요 옵션
  - `--skip-scrape`: 기존 스크래핑 결과를 유지하고 OCR 후처리 단계부터 실행
  - `--stats-only`: 현존하는 결과 파일에 대한 통계만 출력 (스크립트 실행 없음)
  - `--limit`: 수집할 최대 항목 수 제한
  - `--sdate`: 검색 시작일 (형식: YYYY-MM-DD, 기본값: 2025-11-01)
  - `--edate`: 검색 종료일 (형식: YYYY-MM-DD, 기본값: 오늘)
  - `--after`: 이 날짜 이후 항목만 수집
  - `--no-merge`: archive와 병합하지 않고 새 데이터만 저장
  - `--log-file`: 실행 로그를 파일에 저장

## 신규 항목 (257번 이후) 스크래핑 방법

### 자동 스크래핑 (권장)

```bash
# 전체 파이프라인 실행 + 통계 출력
python run_pipeline.py

# 기존 스크래핑 결과로 패턴 추출만 다시 실행하고 싶을 때
python run_pipeline.py --skip-scrape

# 통계만 확인하고 싶을 때
python run_pipeline.py --stats-only

# 실행 로그를 파일에 남기고 싶을 때
python run_pipeline.py --log-file logs/pipeline.log
```

## 내부망(격리망) 환경에서의 준비 사항

외부망이 차단된 환경에서 본 스크립트를 운용할 때는 아래 항목을 사전에 준비해주세요. 단, 금융감독원 제재조치 사이트(`https://www.fss.or.kr`)에 대한 접근만 허용되어 있다고 가정합니다.

1. **Python 런타임**
   - 버전: Python 3.9 이상 권장 (현재 개발은 3.11 기준)
   - 오프라인 설치 파일을 미리 다운로드 후 내부망에 배포하거나, 이미 설치된 레퍼런스를 활용합니다.

2. **필수 패키지 (오프라인 설치 용도)**
   - `requests`, `beautifulsoup4`, `lxml`
   - `pdfplumber`, `PyPDF2`
   - `PyMuPDF`(모듈명 `fitz`), `pytesseract`, `Pillow`
   - 오프라인 환경에서는 위 패키지의 wheel 파일(`*.whl`)을 미리 받아두고, 내부망에서 `pip install --no-index --find-links <wheel_디렉토리>` 방식으로 설치합니다.
   - 다른 내부 자동화 스크립트를 별도로 운용할 계획이라면, 해당 도구가 요구하는 의존성도 오프라인으로 함께 준비해 주세요.

3. **Tesseract-OCR (한글 언어 지원)**
   - 내부망 PC에 Tesseract 실행파일을 설치합니다. (예: `C:\Program Files\Tesseract-OCR\tesseract.exe`)
   - 한글 언어팩(`kor.traineddata`)을 해당 설치 경로의 `tessdata` 디렉토리에 복사합니다.
   - 경로가 표준 위치가 아닐 경우, `ocr_extractor.py`에서 Tesseract 경로를 수정하거나, `pytesseract.pytesseract.tesseract_cmd` 를 환경에 맞게 설정해줍니다.

4. **PDF 처리 관련 라이브러리**
   - `PyPDF2`, `pdfplumber`, `PyMuPDF`은 네트워크가 없어도 PDF 텍스트 추출에 활용됩니다. 오프라인 설치만 해두면 추가적인 인터넷 접근이 필요 없습니다.

5. **스크립트 실행 계정과 권한**
   - 스크립트가 실행될 위치에 대해 읽기/쓰기 권한이 필요합니다. (PDF 임시 저장, JSON/CSV 결과 저장 등)
   - 로그 파일을 별도 디렉터리에 저장할 경우 그 위치에 대한 접근권한도 확인해 주세요.

6. **네트워크 화이트리스트 확인**
   - 금융감독원 제재조치 공개 사이트(`https://www.fss.or.kr/fss/job/openInfo/...`)에 대한 접근이 가능한지 보안팀과 협의합니다.
   - 추가로 PDF 다운로드를 위해 사용하는 `download` 경로 역시 금융감독원 도메인을 사용하므로 동일하게 허용되어야 합니다.

7. **배포 / 업데이트 전략**
   - 내부망으로 코드 업데이트가 어려운 경우, Git 리포지토리의 패키징 버전을 주기적으로 외부에서 받아 USB 등으로 반입합니다.
   - 새로운 패턴 대응 코드를 도입할 때는 해당 모듈(`extract_metadata.py`)과 테스트 데이터(JSON) 등을 함께 반입하여 검증합니다.

8. **옵션 기반 실행**
   - 크론/작업 스케줄러를 사용할 경우, 외부 접근이 차단된 환경에서도 `python run_pipeline.py --log-file logs/pipeline.log` 방식으로 실행 로그를 남길 수 있습니다.
   - 네트워크 부하를 최소화하기 위해 야간이나 업무 외 시간에 실행하는 것을 권장합니다.

**자동 처리 과정:**
1. `fss_sanctions_scraper.py`: 전체 페이지 스크래핑, PDF 다운로드 및 텍스트 추출 (V3 하이브리드 OCR 포함), 메타데이터 추출 → `output/fss_sanc_result.json` 저장
2. `post_process_ocr.py`: OCR 오류 자동 수정 및 품질 검증 (output 파일 처리)
3. archive 병합: OCR 후처리된 데이터를 `archive/fss_sanc_result.json`과 병합하여 저장
4. 통계 출력: 제재내용 추출 성공률 통계 출력

### 방법 2: 명령줄 옵션으로 특정 기간만 스크래핑

`run_pipeline.py`에서 `--sdate`, `--edate` 옵션 사용:

```bash
# 특정 기간만 스크래핑
python run_pipeline.py --sdate 2025-01-01 --edate 2025-12-31 --limit 10

# 특정 날짜 이후 항목만 수집
python run_pipeline.py --after 2025-11-01

# archive와 병합하지 않고 새 데이터만 저장
python run_pipeline.py --no-merge
```

또는 `fss_sanctions_scraper.py` 파일에서 직접 실행:
```bash
python fss_sanctions_scraper.py --sdate 2025-01-01 --edate 2025-12-31 --limit 10
```

## 지원하는 문서 패턴

### 1. 일반 제재 문서
```
3. 제재조치내용
제재대상 제재내용
기관     과태료 18백만원
임원     주의 1명
직원     견책 1명
```

### 2. OCR 텍스트 (공백 포함)
```
3. 제 재 조 치 내 용
제 재 대상   제 재 내 용
기 관       기 관 주 의
직 원       주 의 1 명
```

### 3. 조치내용 변형
```
3. 조치내용
대상    내용
기관    과태료
직원    자율처리필요사항 1건
```

### 4. 재심 케이스
```
Ⅰ. 재심 취지
...
Ⅲ. 재조치 내용
...
```
→ 제재대상: "재심", 제재내용: "재조치 내용 참조"

### 5. 제재대상 없음
```
3. 제재조치내용
- -
(*) 퇴직자 위법사실 통지 제외
```
→ 제재대상: "-", 제재내용: "-"

## 처리 가능한 특수 패턴

### OCR 오인식 정규화
- "로 혐 설 계 사" → "보험설계사"
- "기 관" (공백 있음) → "기관"
- 파이프(|) 구분자 처리

### 다양한 제재대상
- 기관, 임원, 직원, 직원등
- 보험설계사, 보험대리점, 보험중개사
- 개인사업자 (甲, 乙 등 한자 표기)

### 복합 패턴
- 여러 줄에 걸친 제재대상/제재내용
- 제재대상이 중간에 나타나는 경우
- 표 형식이 아닌 서술형

## 필수 요구사항

### Python 패키지
```bash
pip install requests beautifulsoup4 lxml pdfplumber PyPDF2 PyMuPDF pytesseract Pillow
```

### Tesseract-OCR 설치
1. [Tesseract-OCR 다운로드](https://github.com/UB-Mannheim/tesseract/wiki)
2. 설치 시 "Additional language data" > "Korean" 선택
3. 또는 수동으로 `kor.traineddata` 파일을 `C:\Program Files\Tesseract-OCR\tessdata\`에 복사

## 성능 최적화

### OCR 성능 개선
- **해상도**: 300-400 DPI 권장
- **PSM 모드**: 
  - `--psm 6`: 단일 텍스트 블록 (일반 문서)
  - `--psm 4`: 단일 컬럼 (표 형식)
- **한글 언어팩**: `-l kor` 필수

### 처리 속도
- 평균: 약 5-10초/항목
- 총 256개 처리: 약 20-40분
- 서버 부하 방지를 위해 각 요청 사이 1초 대기

## 출력 파일

### `output/fss_sanc_result.json`
- UTF-8 인코딩
- 새로 크롤링한 데이터만 포함
- 전체 제재조치내용 포함
- 프로그래밍 용도에 최적
- OCR 후처리 완료된 데이터

### `output/fss_sanc_result.csv`
- UTF-8-BOM 인코딩 (Excel 한글 호환)
- 새로 크롤링한 데이터만 포함
- 주요 필드만 포함
- 엑셀에서 바로 열기 가능
- OCR 후처리 완료된 데이터

### `archive/fss_sanc_result.json`
- UTF-8 인코딩
- 전체 누적 데이터 (새로 크롤링한 데이터 + 기존 archive 데이터)
- 중복 제거 (제재조치일 + 금융회사명 기준)
- OCR 후처리 완료된 데이터

### `archive/fss_sanc_result.csv`
- UTF-8-BOM 인코딩 (Excel 한글 호환)
- 전체 누적 데이터
- 엑셀에서 바로 열기 가능

### 필드 구조 (영문 키)
```
- dvcv: 구분 (제재사례)
- srce: 출처 (금융감독원)
- fnCompNm: 금융회사명
- btcd: 업종 (은행, 보험, 기타 등)
- snctDt: 제재조치일 (YYYY-MM-DD 형식)
- snctCntn: 제재내용 (표 데이터)
- atchFileUrl: 파일 다운로드 URL
- atchFileNm: 첨부파일명
- tit: 사건제목 (CSV에서 사건이 여러 개인 경우 행 확장)
- cntn: 사건내용 (CSV에서 사건이 여러 개인 경우 행 확장)
- 누락필드: 누락된 필드 목록 (콤마 구분, 없으면 빈 문자열)
```

**참고:** 
- JSON 파일은 영문 키(dvcv, srce, fnCompNm 등)를 사용합니다.
- CSV 파일도 동일한 영문 키를 사용합니다.
- 사건이 여러 개인 경우 CSV에서 각 사건마다 별도의 행으로 확장됩니다.

### 사건제목/사건내용 추출

제재조치내용에서 다양한 섹션 제목을 인식하여 사건제목과 사건내용을 자동으로 추출합니다.

**지원하는 섹션 제목 패턴:**
- `4. 제재대상사실` / `Ⅳ. 제재대상사실` (가장 일반적)
- `4. 조치대상사실` / `Ⅳ. 조치대상사실`
- `4. 제재조치사유` / `Ⅳ. 제재조치사유`
- `4. 제재사유` / `Ⅳ. 제재사유`
- `4. 조치사유` / `Ⅳ. 조치사유`
- `4. 위반내용` / `Ⅳ. 위반내용`
- `4. 사유` / `Ⅳ. 사유`
- `Ⅲ. 재조치 내용 > 2. 재조치대상사실` (재심 케이스)

**지원하는 사건 추출 패턴:**

**타입 1: 기본 패턴 (가. 나. 다.)**
```
4. 제재대상사실

가. 고객위험평가 관련 절차
   (이 부분이 사건 내용)

나. 고객확인제도 관련 절차
   (이 부분이 사건 내용)
```
→ 각각 별도의 사건으로 추출

**타입 2: 문책사항 패턴 (가. 문책사항 > (1) (2))**
```
4. 제재대상사실

가. 문책사항

(1) 직무 관련 정보의 이용 금지 위반
    (이 부분이 사건 내용)
    
(2) 고객확인제도 위반
    (이 부분이 사건 내용)
```
→ 각 (1), (2)가 별도의 사건으로 추출 (상위 제목 "문책사항"은 접두사로 사용하지 않음)

**타입 3: 통합 사건 모드 (가. 일반제목 > 모든 (1), (2)를 하나로)**
```
4. 제재대상사실

가. 은행 대주주 특수관계인에 대한 신용공여 절차 위반

(1) 이사회 의결 미실시
    (이 부분이 내용)
    
(2) 보고 및 공시 의무 위반
    (이 부분도 같은 사건의 내용)
```
→ 모든 (1), (2)가 하나의 사건 내용으로 통합됨

**타입 4: 중첩 구조 (가. > (1) > (가) (나))**
```
4. 제재대상사실

가. 문책사항

(1) 투자자 보호의무 위반
    (가) 고객 정보 미확인
    (나) 부적합 상품 판매
    
(2) 내부통제 미흡
```
→ (가), (나)는 내용으로 처리, (1), (2)는 각각 별도 사건

**타입 5: 가. 패턴 없이 바로 (1) 시작**
```
4. 제재대상사실

(1) 고객확인의무 위반
    (이 부분이 사건 내용)
    
(2) 거래제한 의무 위반
    (이 부분이 사건 내용)
```
→ 각 (1), (2)가 별도의 사건으로 추출

**타입 6: 사각형/원형 기호 패턴 (가. 패턴이 없을 때)**
```
4. 제재대상사실

□ 고객확인의무 위반
  ◦ 고객 정보 미확인
  ◦ 추가 정보 확인 누락
```
→ "□"로 시작하는 줄은 제목, "◦"로 시작하는 줄은 내용

**타입 7: 재조치 내용 패턴**
```
Ⅲ. 재조치 내용

2. 재조치대상사실

가. 문책사항
(1) 동일인 대출한도 초과 취급
    (이 부분이 사건 내용)
```
→ 재심/재조치 케이스에서 "재조치대상사실" 섹션에서 추출

**상위 제목 지원:**
- 문책사항, 책임사항
- 자율처리 필요사항
- 경영유의, 경영유의사항
- 개선사항
- 주의사항

→ 이 키워드가 포함된 경우 각 (1), (2)를 별도 사건으로 처리하며, 상위 제목은 접두사로 사용하지 않음

**저장 형식:**
- 사건이 여러 개인 경우 CSV에서 각 사건마다 별도의 행으로 확장됩니다.
- JSON에서는 각 항목에 `tit`(제목), `cntn`(내용) 필드로 저장되며, 사건이 여러 개인 경우 `tit1`, `cntn1`, `tit2`, `cntn2` 등의 형식으로 저장됩니다.
- 상위 제목이 있는 경우: "상위제목 - 하위제목" 형식으로 저장 (단, 특수 키워드는 제외)

## 문제 해결

### OCR 오류
```bash
# 1. Tesseract 설치 확인
tesseract --version

# 2. 한글 언어팩 확인
tesseract --list-langs
```

### 인코딩 오류
- Windows: `sys.stdout.reconfigure(encoding='utf-8')`
- CSV: `encoding='utf-8-sig'` 사용 (BOM 포함)

### 패턴 인식 실패
1. `extract_metadata.py`에 새로운 패턴 추가
2. 정규표현식 수정
3. 테스트 후 전체 재실행

## 유지보수 체크리스트

### 신규 항목 추가 시
- [ ] `run_pipeline.py` 실행 (또는 `fss_sanctions_scraper.py` 실행)
- [ ] `output/fss_sanc_result.json` 확인 (새로 크롤링한 데이터)
- [ ] `archive/fss_sanc_result.json` 확인 (전체 누적 데이터)
- [ ] 결과 CSV 파일 확인
- [ ] 특이 케이스 수동 검토

### 패턴 업데이트 시
- [ ] 새로운 패턴 확인
- [ ] `extract_metadata.py`에 패턴 추가
- [ ] 테스트 항목으로 검증 (`--limit` 옵션 사용)
- [ ] 전체 데이터 재추출

### Archive 데이터 관리
- [ ] `archive/fss_sanc_result.json`: 전체 누적 데이터 (백업 권장)
- [ ] `output/fss_sanc_result.json`: 최신 스크래핑 결과만 (임시 파일)
- [ ] 중복 제거: 제재조치일 + 금융회사명 기준으로 자동 처리

## 참고사항

### 금융감독원 웹사이트
- URL: https://www.fss.or.kr/fss/job/openInfo/list.do
- 메뉴: 업무안내 > 공시 > 제재조치내용 공개

### 데이터 업데이트 주기
- 금융감독원은 부정기적으로 제재조치를 공개
- 주기적으로 스크래핑하여 신규 항목 확인 필요
- `archive/fss_sanc_result.json`에 전체 데이터가 누적되어 관리됨

### Archive 병합 기능
- 새로 크롤링한 데이터를 기존 archive 데이터와 자동 병합
- 중복 제거: 제재조치일 + 금융회사명이 동일한 경우 새 데이터 제외
- OCR 후처리 완료 후 병합되어 최종 archive 데이터 품질 보장
- `--no-merge` 옵션으로 archive 병합 생략 가능
- 실행 순서: 스크래핑 → OCR 후처리 → archive 병합 → 통계 출력

### Archive 병합 기능
- 새로 크롤링한 데이터를 기존 archive 데이터와 자동 병합
- 중복 제거: 제재조치일 + 금융회사명이 동일한 경우 새 데이터 제외
- OCR 후처리 완료 후 병합되어 최종 archive 데이터 품질 보장
- `--no-merge` 옵션으로 archive 병합 생략 가능

---

## 완료 체크

- [x] 260개 항목 스크래핑 및 후처리 완료 (100%)
- [x] 일반 제재 패턴 인식
- [x] OCR 텍스트 처리
- [x] 재심 케이스 처리
- [x] 제재대상 없음 처리
- [x] JSON/CSV 출력
- [x] 한글 인코딩 최적화

**모든 패턴이 구현되어 257번 이후 신규 항목도 자동 처리 가능합니다!**

